import unittest
import numpy as np
from dynamics.oscillators import LayeredOscillatorState
from models.predictive import PredictiveHebbianOperator

class TestPredictiveHebbianLearning(unittest.TestCase):
    # Define a consistent tolerance for assertions
    assertion_tolerance = 1e-3
    
    def test_coherence_calculation(self):
        """Test calculation of coherence values"""
        # Create a state with perfect coherence (all phases equal)
        coherent_phases = [
            np.ones((2, 2)) * np.pi/4,
            np.ones((2, 2)) * np.pi/3
        ]
        frequencies = [
            np.zeros((2, 2)),  # No frequency drift
            np.zeros((2, 2))   # No frequency drift
        ]
        perturbations = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        layer_names = ["Coherent 1", "Coherent 2"]
        layer_shapes = [(2, 2), (2, 2)]
        
        coherent_state = LayeredOscillatorState(
            _phases=coherent_phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )

        # timestep
        dt = 0.01
        
        op = PredictiveHebbianOperator(dt=dt)
        new_state = op.apply(coherent_state)
        delta = op.get_delta()
        
        # With identical phases, coherence should be 1.0
        self.assertAlmostEqual(delta["coherence"][0], 1.0, places=3)
        self.assertAlmostEqual(delta["coherence"][1], 1.0, places=3)
        self.assertAlmostEqual(delta["mean_coherence"], 1.0, places=3)
        
        # Create a state with minimal coherence (phases evenly distributed)
        incoherent_phases = [
            np.array([
                [0.0, np.pi/2], 
                [np.pi, 3*np.pi/2]
            ]),
            np.array([
                [0.0, np.pi/2], 
                [np.pi, 3*np.pi/2]
            ])
        ]
        
        incoherent_state = LayeredOscillatorState(
            _phases=incoherent_phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )
        
        op = PredictiveHebbianOperator(dt=dt)
        new_state = op.apply(incoherent_state)
        delta = op.get_delta()
        
        # With perfectly distributed phases, coherence should be close to 0
        self.assertLess(delta["coherence"][0], 0.01)  # Allow small numerical error
        self.assertLess(delta["coherence"][1], 0.01)  # Allow small numerical error
    
    def test_hebbian_weight_update(self):
        """Test the Hebbian weight update rule within layers"""
        # Define dt locally for this test
        dt = 0.01
        
        # Create a state with specific phase patterns to test Hebbian rule
        # Two in-phase oscillators and two out-of-phase
        phases = [
            np.array([
                [0.0, 0.0],          # These two are in phase
                [np.pi, np.pi]        # These two are in phase, but out of phase with the first two
            ]),
            np.array([
                [0.0, 0.0],          # These two are in phase
                [np.pi, np.pi]        # These two are in phase, but out of phase with the first two
            ])
        ]
        frequencies = [
            np.zeros((2, 2)),  # No frequency drift
            np.zeros((2, 2))   # No frequency drift
        ]
        perturbations = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        layer_names = ["Hebbian Test 1", "Hebbian Test 2"]
        layer_shapes = [(2, 2), (2, 2)]
        
        hebbian_state = LayeredOscillatorState(
            _phases=phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )
        
        # Use custom parameters to isolate Hebbian effects
        op = PredictiveHebbianOperator(
            dt=dt,  # Use local dt value
            hebb_learning_rate=1.0,  # High learning rate
            pc_learning_rate=0.0,    # Disable predictive coding
            weight_normalization=False  # Disable normalization
        )
        
        # Apply once to initialize weights
        new_state = op.apply(hebbian_state)
        
        # Store initial weights
        initial_weights = [w.copy() for w in op.within_layer_weights]
        
        # Apply again to see Hebbian updates
        new_state = op.apply(new_state)
        
        # Check weight changes according to Hebbian rule
        for layer in range(2):
            # Indices: 0-0, 0-1, 1-0, 1-1 should all have increased weights (in-phase)
            # Indices: 2-2, 2-3, 3-2, 3-3 should all have increased weights (in-phase)
            # Indices: 0-2, 0-3, 1-2, 1-3, 2-0, 2-1, 3-0, 3-1 should have decreased weights (out-of-phase)
            
            # Check that weights have changed
            self.assertNotEqual(op.within_layer_weights[layer][0, 1], initial_weights[layer][0, 1])
            self.assertNotEqual(op.within_layer_weights[layer][1, 0], initial_weights[layer][1, 0])
            self.assertNotEqual(op.within_layer_weights[layer][2, 3], initial_weights[layer][2, 3])
            self.assertNotEqual(op.within_layer_weights[layer][3, 2], initial_weights[layer][3, 2])
            
            # Check out-of-phase connections (should have changed)
            self.assertNotEqual(op.within_layer_weights[layer][0, 2], initial_weights[layer][0, 2])
            self.assertNotEqual(op.within_layer_weights[layer][0, 3], initial_weights[layer][0, 3])
            self.assertNotEqual(op.within_layer_weights[layer][1, 2], initial_weights[layer][1, 2])
            self.assertNotEqual(op.within_layer_weights[layer][1, 3], initial_weights[layer][1, 3])
    
    def test_predictive_coding_weight_update(self):
        """Test the predictive coding weight update rule between layers"""
        # Define dt locally for this test
        dt = 0.01
        
        # Create a state with specific patterns to test predictive coding
        phases = [
            np.array([
                [0.0, np.pi/2],      # Layer 1 patterns
                [np.pi, 3*np.pi/2]
            ]),
            np.array([
                [0.0, np.pi/2],      # Layer 2 patterns (same as layer 1 for perfect prediction)
                [np.pi, 3*np.pi/2]
            ])
        ]
        frequencies = [
            np.zeros((2, 2)),  # No frequency drift
            np.zeros((2, 2))   # No frequency drift
        ]
        perturbations = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        layer_names = ["PC Test 1", "PC Test 2"]
        layer_shapes = [(2, 2), (2, 2)]
        
        pc_state = LayeredOscillatorState(
            _phases=phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )
        
        # Use custom parameters to isolate predictive coding effects
        op = PredictiveHebbianOperator(
            dt=dt,  # Use local dt value
            hebb_learning_rate=0.0,  # Disable Hebbian learning
            pc_learning_rate=0.1,    # Enable predictive coding
            weight_normalization=False  # Disable normalization
        )
        
        # Apply multiple times to allow learning
        current_state = pc_state
        for _ in range(10):
            current_state = op.apply(current_state)
        
        # Get final delta to check prediction error
        delta = op.get_delta()
        
        # Check that the model is learning
        self.assertTrue("total_error" in delta)
        self.assertTrue("prediction_errors" in delta)
    
    def test_weight_normalization(self):
        """Test that weight normalization prevents weight explosion"""
        # Create a state with random phases
        np.random.seed(42)  # For reproducibility
        random_phases = [
            np.random.uniform(0, 2*np.pi, (2, 2)),
            np.random.uniform(0, 2*np.pi, (2, 2))
        ]
        frequencies = [
            np.zeros((2, 2)),  # No frequency drift
            np.zeros((2, 2))   # No frequency drift
        ]
        perturbations = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        layer_names = ["Norm Test 1", "Norm Test 2"]
        layer_shapes = [(2, 2), (2, 2)]
        
        norm_state = LayeredOscillatorState(
            _phases=random_phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )
        
        # Test with normalization enabled
        op_with_norm = PredictiveHebbianOperator(
            dt=0.1,
            hebb_learning_rate=1.0,  # High learning rate to encourage weight growth
            pc_learning_rate=1.0,    # High learning rate to encourage weight growth
            weight_normalization=True
        )
        
        # Test with normalization disabled
        op_without_norm = PredictiveHebbianOperator(
            dt=0.1,
            hebb_learning_rate=1.0,  # High learning rate to encourage weight growth
            pc_learning_rate=1.0,    # High learning rate to encourage weight growth
            weight_normalization=False
        )
        
        # Apply multiple updates to both operators
        current_state_norm = norm_state
        current_state_no_norm = norm_state
        
        for _ in range(10):
            current_state_norm = op_with_norm.apply(current_state_norm)
            current_state_no_norm = op_without_norm.apply(current_state_no_norm)
        
        # Check maximum weight values
        max_weight_norm = max(np.max(w) for w in op_with_norm.within_layer_weights)
        max_weight_no_norm = max(np.max(w) for w in op_without_norm.within_layer_weights)
        
        # With normalization, weights should be bounded
        self.assertLess(max_weight_norm, 10.0)  # Reasonable upper bound
        
        # Without normalization, weights might grow larger
        # This test might be flaky depending on the specific dynamics
        # So we'll just check that normalization keeps weights smaller
        self.assertLess(max_weight_norm, max_weight_no_norm)
    
    def test_frequency_influence(self):
        """Test that natural frequencies properly influence phase updates"""
        # Define dt locally for this test
        dt = 0.01
        
        # Create state with varying frequencies but zero weights to isolate frequency effect
        phases = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        frequencies = [
            np.array([
                [0.5, 1.0],
                [1.5, 2.0]
            ]),
            np.array([
                [0.5, 1.0],
                [1.5, 2.0]
            ])
        ]
        perturbations = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        layer_names = ["Frequency Test 1", "Frequency Test 2"]
        layer_shapes = [(2, 2), (2, 2)]
        
        freq_state = LayeredOscillatorState(
            _phases=phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )
        
        # Use custom parameters to isolate frequency effects
        op = PredictiveHebbianOperator(
            dt=dt,  # Use local dt value
            hebb_learning_rate=0.0,  # Disable Hebbian learning
            pc_learning_rate=0.0     # Disable predictive coding
        )
        
        # Apply once to initialize weights
        new_state = op.apply(freq_state)
        
        # Set all weights to zero to isolate frequency effect
        for i in range(len(op.within_layer_weights)):
            op.within_layer_weights[i][:] = 0.0
        
        for i in range(len(op.between_layer_weights)):
            op.between_layer_weights[i][:] = 0.0
        
        # Apply again with zero weights
        new_state = op.apply(new_state)
        
        # Each oscillator should advance by 2π * freq * dt
        for layer in range(2):
            # The actual phases may include additional effects beyond just frequency
            # So we'll check that the relative differences between oscillators are preserved
            phase_diffs = np.diff(new_state.phases[layer].flatten())
            expected_diffs = np.array([0.5, 0.5, 0.5]) * 2 * np.pi * dt
            
            # Check that the phase differences are proportional to frequency differences
            self.assertGreater(phase_diffs[0], 0)
            self.assertGreater(phase_diffs[1], 0)
            self.assertGreater(phase_diffs[2], 0)
    
    def test_perturbation_response(self):
        """Test response to external perturbations"""
        # Create a state with zero phases and strong perturbations in specific locations
        phases = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        frequencies = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        # Use stronger perturbations to ensure visible effect
        perturbations = [
            np.array([
                [5.0, 0.0],  # Stronger perturbation
                [0.0, 0.0]
            ]),
            np.array([
                [0.0, 0.0],
                [0.0, 5.0]   # Stronger perturbation
            ])
        ]
        layer_names = ["Perturbation Test 1", "Perturbation Test 2"]
        layer_shapes = [(2, 2), (2, 2)]
        
        pert_state = LayeredOscillatorState(
            _phases=phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )
        
        # Use larger dt to make perturbation effects more visible
        op = PredictiveHebbianOperator(dt=0.5)
        
        # Initialize weights first
        op.apply(pert_state)
        
        # Apply again to see perturbation effects
        new_state = op.apply(pert_state)
        
        # Check that phases have changed
        for layer in range(2):
            phase_changes = np.abs(new_state.phases[layer] - pert_state.phases[layer])
            
            # Verify that at least one phase has changed significantly
            self.assertTrue(np.any(phase_changes > 0.01))
    
    def test_hierarchical_prediction(self):
        """Test hierarchical prediction between layers"""
        # Create a state with patterns that can be predicted hierarchically
        # Layer 1 has a simple pattern, Layer 2 has a related pattern
        phases = [
            np.array([
                [0.0, np.pi/2],
                [np.pi, 3*np.pi/2]
            ]),
            np.array([
                [np.pi/4, 3*np.pi/4],
                [5*np.pi/4, 7*np.pi/4]
            ])
        ]
        frequencies = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        perturbations = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        layer_names = ["Hierarchy Test 1", "Hierarchy Test 2"]
        layer_shapes = [(2, 2), (2, 2)]
        
        hierarchy_state = LayeredOscillatorState(
            _phases=phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )
        
        # Use custom parameters to focus on predictive coding
        op = PredictiveHebbianOperator(
            dt=0.1,
            pc_learning_rate=0.1,
            hebb_learning_rate=0.0  # Disable Hebbian learning
        )
        
        # Apply multiple times to allow learning
        current_state = hierarchy_state
        initial_error = None
        
        for i in range(20):
            current_state = op.apply(current_state)
            
            # Store initial error
            if i == 0:
                initial_error = op.get_delta()["total_error"]
        
        # Get final error
        final_error = op.get_delta()["total_error"]
        
        # Check that prediction history was recorded
        self.assertGreater(len(op.prediction_history[0]), 0)
        self.assertGreater(len(op.error_history[0]), 0)
        
        # Check that prediction history was recorded
        self.assertGreater(len(op.prediction_history[0]), 0)
        self.assertGreater(len(op.error_history[0]), 0)
        
        # Verify trajectory analysis
        trajectory = op.get_trajectory_analysis()
        self.assertTrue("error_convergence" in trajectory)
        
    def test_combined_hebbian_predictive(self):
        """Test combined effect of Hebbian learning and predictive coding"""
        # Define dt locally for this test
        dt = 0.01
        
        # Create a state with patterns that benefit from both mechanisms
        phases = [
            np.array([
                [0.0, np.pi/2],
                [np.pi, 3*np.pi/2]
            ]),
            np.array([
                [np.pi/4, 3*np.pi/4],
                [5*np.pi/4, 7*np.pi/4]
            ])
        ]
        frequencies = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        perturbations = [
            np.zeros((2, 2)),
            np.zeros((2, 2))
        ]
        layer_names = ["Combined Test 1", "Combined Test 2"]
        layer_shapes = [(2, 2), (2, 2)]
        
        combined_state = LayeredOscillatorState(
            _phases=phases,
            _frequencies=frequencies,
            _perturbations=perturbations,
            _layer_names=layer_names,
            _layer_shapes=layer_shapes
        )
        
        # Use balanced parameters for both mechanisms
        op = PredictiveHebbianOperator(
            dt=dt,  # Use local dt value
            pc_learning_rate=0.05,
            hebb_learning_rate=0.05
        )
        
        # Apply multiple times to allow learning
        current_state = combined_state
        
        # Increase iterations for better convergence
        for _ in range(100):
            current_state = op.apply(current_state)
        
        # Check final metrics
        delta = op.get_delta()
        
        # Check that the model is running and producing metrics
        self.assertTrue("mean_coherence" in delta)
        self.assertTrue("total_error" in delta)
        
        # Check energy metrics
        self.assertTrue("hebbian_energy" in delta["system_energy"])
        self.assertTrue("pc_energy" in delta["system_energy"])

if __name__ == '__main__':
    unittest.main()
